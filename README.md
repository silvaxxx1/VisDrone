# ğŸš VisDrone Object Detection â€“ Technofest Project

Welcome to the **VisDrone YOLOv11n Inference Demo**, part of our **Technofest Competition Submission**. This project focuses on detecting objects from drone-based video footage using a custom-trained **YOLOv11n** model.

> ğŸ¯ This repository will eventually include the **full pipeline** â€” from training to inference â€” for drone-based object detection.

---

## ğŸ“‚ Current Contents

- `inf.py` â€“ Inference script that processes a drone video, displays live detections, and saves the annotated output.
- `.gitignore` â€“ Excludes large model/video files from version control.

---

## ğŸš€ How to Use

1. Place your custom-trained model (`Vis.pt`) and input drone video (`demo.MP4`) in the root directory.
2. Run the inference script:
   ```bash
   python inf.py
   ```
3. Output video (`output_demo.mp4`) will be saved in the same directory.

---

## ğŸ›  Requirements

- Python 3.8+
- [Ultralytics](https://github.com/ultralytics/ultralytics)
- OpenCV
- PyTorch (CUDA support recommended)

Install them with:
```bash
pip install ultralytics opencv-python torch
```

---

## ğŸ§  Model Info

We're using the lightweight and fast **YOLOv11n** model, trained on a drone-perspective dataset (`Vis.pt`), tailored for real-time detection from aerial views.

---

## ğŸ›¤ Future Plans

This repository will grow to include:

- ğŸ“¦ Dataset preprocessing
- ğŸ§‘â€ğŸ« Model training & evaluation
- ğŸ§ª Experiment logging
- ğŸ’¾ Model export (ONNX, TorchScript)
- ğŸŒ Deployment options (API, web app, edge device)

---

## ğŸ¤ Credits

This work is part of the **SILVA.AI Lab** project submission for **Technofest 2025**.

---

## ğŸ“¢ Note

Model weights (`*.pt`) and videos (`*.mp4`) are **excluded** from the repository via `.gitignore` to keep the repo clean.

```

